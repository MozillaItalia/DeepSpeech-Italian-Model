{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBVpKaIDxr5n"
   },
   "source": [
    "# <h1> A COLAB notebook for italian DeepSpeech model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-6vTdO315En"
   },
   "source": [
    "## Install all the needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nf0QISLC2nes",
    "outputId": "f63fff12-6432-45a6-a8d5-67f163e3f3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "# shortcut for /root folder\n",
    "H = %env HOME\n",
    "%cd $H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "qK-aUbVj8Eey",
    "outputId": "86e902ae-628d-41e1-ac72-df79fe1a61df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n",
      "Cloning into './ds'...\n",
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 18619 (delta 8), reused 8 (delta 2), pack-reused 18594\u001b[K\n",
      "Receiving objects: 100% (18619/18619), 47.71 MiB | 26.37 MiB/s, done.\n",
      "Resolving deltas: 100% (12675/12675), done.\n",
      "/root/ds\n",
      "Note: checking out '88584941bc2ff5b91d6b11ad0a6b85da391d626b'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at 88584941 Merge pull request #3036 from lissyx/doc-fix\n"
     ]
    }
   ],
   "source": [
    "%env DS_VERSION 0.8.0\n",
    "# Get DeepSpeech\n",
    "\n",
    "%cd $H\n",
    "!git clone https://github.com/mozilla/DeepSpeech.git ./ds\n",
    "%cd ds\n",
    "!git checkout f56b07dab4542eecfb72e059079db6c2603cc0ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJjv6XhA11E6"
   },
   "outputs": [],
   "source": [
    "# needed for kenlm.scorer (eg  for bin/run-ldc93s1.sh ). Commented for space availability reason\n",
    "\n",
    "# !apt-get install git-lfs\n",
    "# !git-lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5k0Pegar2_7w",
    "outputId": "19777507-9779-454f-b738-ef5e4fbede46"
   },
   "outputs": [],
   "source": [
    "# Tell colab to use TF 1.x version and then install DS dependencies\n",
    "%tensorflow_version 1.x\n",
    "!pip3 install --no-cache-dir --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3\n",
    "!pip3 install --no-cache-dir --upgrade -e .\n",
    "!apt update\n",
    "!apt-get install sox libsox-fmt-mp3 pixz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LPiM0nZ88Yfm",
    "outputId": "3f106dd3-62f6-4b4a-fd7a-d42fb4efccf4"
   },
   "outputs": [],
   "source": [
    "# simple check before going on\n",
    "!./bin/run-tc-ldc93s1_new.sh 2 16000\n",
    "\n",
    "# this one need the kenlm.scorer so you need to install git-lfs and do a \n",
    "# git-fls pull in the deepspeech repo\n",
    "# !./bin/run-ldc93s1.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "33pDRwMPO214",
    "outputId": "1b7245d4-95ed-480f-8b64-10870534a5d5"
   },
   "outputs": [],
   "source": [
    "#extract the tiny cv sample dataset\n",
    "!mkdir -p /mnt/extracted/data/cv-it_tiny\n",
    "%env CV_TINY_PATH /mnt/extracted/data/cv-it_tiny\n",
    "!wget -O - https://github.com/MozillaItalia/DeepSpeech-Italian-Model/files/4610711/cv-it_tiny.tar.gz | tar -zxv -C $CV_TINY_PATH\n",
    "\n",
    "#and the italian alphabet\n",
    "!mkdir -p /mnt/models\n",
    "!wget -O \"/mnt/models/alphabet.txt\" https://github.com/MozillaItalia/DeepSpeech-Italian-Model/raw/master/DeepSpeech/italian_alphabet.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQ-pzO3O3cEt"
   },
   "source": [
    "## CV-IT and MAILABS complete dataset\n",
    "\n",
    "**WARNING: the remaining space disk will not be enough to save training checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ladVQoVJ9drR",
    "outputId": "b2a22fe7-0881-4c7e-fc4d-e0859311c7c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment here if you want the CV-IT and MAILABS complete datasets\n",
    "# Keep in mind that all these stuff decompressed takes around 30GB\n",
    "# Note: english compatibility is not handled right now\n",
    "\n",
    "#MAILABS\n",
    "'''\n",
    "\n",
    "%cd $H/ds\n",
    "# Download and prepare M-AILABS\n",
    "!python bin/import_m-ailabs.py ${IMPORT_AS_ENGLISH} \\\n",
    "  --filter_alphabet /mnt/models/alphabet.txt \\\n",
    "  --language it_IT                           \\\n",
    "  /mnt/extracted/data/M-AILABS/\n",
    "# free some space removing the MAILABS tgz\n",
    "!rm /mnt/extracted/data/M-AILABS/it_IT.tgz\n",
    "\n",
    "'''\n",
    "\n",
    "# CV-IT\n",
    "'''\n",
    "%cd $H/ds\n",
    "# Download CV\n",
    "!mkdir -p /mnt/sources\n",
    "!wget https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-4-2019-12-10/it.tar.gz -O /mnt/sources/it.tar.gz\n",
    "# Prepare CV\n",
    "!mkdir -p /mnt/extracted/data/cv-it/\n",
    "!tar -C /mnt/extracted/data/cv-it/ -xf /mnt/sources/it.tar.gz\n",
    "!python bin/import_cv2.py --filter_alphabet=/mnt/models/alphabet.txt /mnt/extracted/data/cv-it/\n",
    "# free some space again\n",
    "!rm /mnt/sources/it.tar.gz\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "O79LJ8UxrxQq",
    "outputId": "b65c63cd-e82c-4b6d-df91-9b01b9d4a85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 1.5.0+cu101\n",
      "Uninstalling torch-1.5.0+cu101:\n",
      "  Successfully uninstalled torch-1.5.0+cu101\n"
     ]
    }
   ],
   "source": [
    "# Run this if you need some space\n",
    "!rm -rf /swift/*\n",
    "!pip uninstall -y torch\n",
    "!rm -rf $H/.cache/pip/*\n",
    "!rm -rf $H/DeepSpeech-Italian-Model/.git/*\n",
    "!rm -rf $H/ds/.git/*\n",
    "!rm -rf $H/kenlm/.git/*\n",
    "!rm -rf /content/sample_data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vmJT9fZfHv9"
   },
   "source": [
    "## **Setup your google drive now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-axrZPOUr9f"
   },
   "source": [
    "Please, before running other cells, export your google drive path to store your model checkpoints.\n",
    "\n",
    "Probably you'll need more space than colab offers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfwjPUAB21Dt"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "30FPr_a97TD1",
    "outputId": "d16a54f2-3f20-41b7-a64e-94cca95c1499"
   },
   "outputs": [],
   "source": [
    "# Save your google drive path\n",
    "%env GDRIVE_PATH /your/path/to/drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FXM5KLfAvzv"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqoH_ho9VY_V"
   },
   "source": [
    "### Download DeepSpeech checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "14L-a3abd659",
    "outputId": "9e6b92c0-9f6e-4d10-970b-058c59393d1c"
   },
   "outputs": [],
   "source": [
    "!wget -O - \"https://github.com/mozilla/DeepSpeech/releases/download/v$DS_VERSION/deepspeech-$DS_VERSION-checkpoint.tar.gz\" | tar -zxv -C \"$GDRIVE_PATH/$DS_VERSION/transfer_ckpts/eng\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7e62swUV02y"
   },
   "source": [
    "### Setup all needed params and paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7GPiNTuPAkPs",
    "outputId": "820115a1-7045-45d6-d443-df94d3561a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do early stop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# lets put some model params\n",
    "\n",
    "BATCH_SIZE=2 #128 from 0.7 release\n",
    "N_HIDDEN=2048\n",
    "EPOCHS=30\n",
    "LEARNING_RATE=0.0001\n",
    "DROPOUT=0.4 # from 0.7 release\n",
    "LM_ALPHA = None # 0.931289039105002 # from 0.7 release\n",
    "LM_BETA= None # 1.1834137581510284 # from 0.7 release\n",
    "# BEAM_WIDTH=500\n",
    "do_early_stop= True\n",
    "use_amp= False # DS checkpoint are not compatible with AMP\n",
    "\n",
    "#transfer params\n",
    "DROP_SOURCE_LAYERS = 1\n",
    "\n",
    "#other flags\n",
    "MAX_TO_KEEP = 3 # max nr of checkpoints to keep\n",
    "\n",
    "EARLY_STOP_FLAG=\"--noearly_stop\"\n",
    "if do_early_stop:\n",
    "  print(\"do early stop\")\n",
    "  EARLY_STOP_FLAG=\"--early_stop\"\n",
    "\n",
    "AMP_FLAG=\"\"\n",
    "if use_amp:\n",
    "  print(\"use automatic mixed precision\")\n",
    "  AMP_FLAG=\"--automatic_mixed_precision true\"\n",
    "\n",
    "!mkdir -p /mnt/sources/feature_cache || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "zbnvvYK6Ow9V",
    "outputId": "dc18b692-17a2-47d5-e865-9077444930bc"
   },
   "outputs": [],
   "source": [
    "# Some paths\n",
    "\n",
    "# Customize them based on your needs!\n",
    "\n",
    "paths2print = []\n",
    "\n",
    "ALPHABET_CONFIG_PATH=\"/mnt/models/alphabet.txt\"\n",
    "paths2print.append(ALPHABET_CONFIG_PATH)\n",
    "\n",
    "SAVE_CHECKPOINT_DIR = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.7/transfer_ckpts/ita\")\n",
    "paths2print.append(SAVE_CHECKPOINT_DIR)\n",
    "LOAD_CHECKPOINT_DIR = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.7/transfer_ckpts/eng/deepspeech-\"+os.environ.get(\"DS_VERSION\")+\"-checkpoint\")\n",
    "paths2print.append(LOAD_CHECKPOINT_DIR)\n",
    "\n",
    "# when you set 2 different dir during training, deepspeech will warn you that it will\n",
    "# be impossibile to evaluate the model with the test dataset.\n",
    "CHECKPOINT_DIR = SAVE_CHECKPOINT_DIR\n",
    "paths2print.append(CHECKPOINT_DIR)\n",
    "\n",
    "SCORER = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.7/kenlm.scorer\")\n",
    "paths2print.append(SCORER)\n",
    "\n",
    "EXPORT_FOLDER = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.7\")\n",
    "paths2print.append(EXPORT_FOLDER)\n",
    "\n",
    "# dir for tensorboard and logs\n",
    "SUMMARY_DIR = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.7/logs\")\n",
    "paths2print.append(SUMMARY_DIR)\n",
    "\n",
    "# just for a quick check \n",
    "for p in paths2print:\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkFqEJWhMhJV"
   },
   "outputs": [],
   "source": [
    "# Train, dev and test as list of path to .csv files\n",
    "# Note: each dataset needs to be located under /mnt/extracted/data\n",
    "\n",
    "all_train_csv=!(find /mnt/extracted/data/ -type f -name '*train.csv' -printf '%p,' | sed -e 's/,$//g')\n",
    "all_dev_csv=!(find /mnt/extracted/data/ -type f -name '*dev.csv' -printf '%p,' | sed -e 's/,$//g')\n",
    "all_test_csv=!(find /mnt/extracted/data/ -type f -name '*test.csv' -printf '%p,' | sed -e 's/,$//g')\n",
    "ALL_TRAIN_CSV=all_train_csv[0]\n",
    "ALL_DEV_CSV=all_dev_csv[0]\n",
    "ALL_TEST_CSV=all_test_csv[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-wlOBFwzSUc5",
    "outputId": "5e44fe26-3586-4993-ba83-1ad3698650be"
   },
   "outputs": [],
   "source": [
    "# Build the params string for DeepSpeech.py\n",
    "\n",
    "'''\n",
    "Note if your paths contain spaces just wrap them inside \" \"\n",
    "eg:\n",
    "\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "\n",
    "'''\n",
    "\n",
    "params = \"\"\n",
    "\n",
    "# Using default lm_alpha and lm_beta \n",
    "train_params = ' \\\n",
    "--summary_dir \"'+SUMMARY_DIR+'\" \\\n",
    "--log_dir \"'+SUMMARY_DIR+'\" \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--train_cudnn True \\\n",
    "'+AMP_FLAG+' \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--train_files '+ALL_TRAIN_CSV+' \\\n",
    "--dev_files '+ALL_DEV_CSV+' \\\n",
    "--train_batch_size '+str(BATCH_SIZE)+' \\\n",
    "--dev_batch_size '+str(BATCH_SIZE)+' \\\n",
    "--n_hidden '+str(N_HIDDEN)+' \\\n",
    "--epochs '+str(EPOCHS)+' \\\n",
    "--learning_rate '+str(LEARNING_RATE)+' \\\n",
    "--dropout_rate '+str(DROPOUT)+' \\\n",
    "--max_to_keep '+str(MAX_TO_KEEP)+' \\\n",
    "'+EARLY_STOP_FLAG\n",
    "\n",
    "params = train_params\n",
    "\n",
    "# If you dont want to use data augmentation, flag this on False\n",
    "use_augmentation = True\n",
    "# transfer learning on/off\n",
    "do_transfer_learning = True\n",
    "\n",
    "\n",
    "if do_transfer_learning:\n",
    "  transfer_params = '\\\n",
    "  --drop_source_layers '+str(DROP_SOURCE_LAYERS)+'\\\n",
    "  --save_checkpoint_dir \"'+SAVE_CHECKPOINT_DIR+'\" \\\n",
    "  --load_checkpoint_dir \"'+LOAD_CHECKPOINT_DIR+'\"'\n",
    "\n",
    "  params+=transfer_params\n",
    "\n",
    "if use_augmentation:\n",
    "  augm = '\\\n",
    "  --feature_cache /mnt/sources/feature_cache \\\n",
    "  --cache_for_epochs 10 \\\n",
    "  --augment reverb[p=0.1,delay=50.0~30.0,decay=10.0:2.0~1.0] \\\n",
    "  --augment resample[p=0.1,rate=12000:8000~4000] \\\n",
    "  --augment codec[p=0.1,bitrate=48000:16000] \\\n",
    "  --augment volume[p=0.1,dbfs=-10:-40] \\\n",
    "  --augment pitch[p=0.1,pitch=1~0.2] \\\n",
    "  --augment tempo[p=0.1,factor=1~0.5] \\\n",
    "  --augment frequency_mask[p=0.1,n=1:3,size=1:5] \\\n",
    "  --augment time_mask[p=0.1,domain=signal,n=3:10~2,size=50:100~40] \\\n",
    "  --augment dropout[p=0.1,rate=0.05] \\\n",
    "  --augment add[p=0.1,domain=signal,stddev=0~0.5] \\\n",
    "  --augment multiply[p=0.1,domain=features,stddev=0~0.5]'\n",
    "  params+=augm\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28CMI8f7WJHX"
   },
   "source": [
    "### Start the training phase!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "aoiWWxQlGSC6",
    "outputId": "2a3eca7b-564a-4425-c4d0-fe3c38c8ad97"
   },
   "outputs": [],
   "source": [
    "%cd $H/ds/\n",
    "!set -xe\n",
    "!python DeepSpeech.py $params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"$SUMMARY_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeMf4QiUWnJl"
   },
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h7KomzFFp4aV",
    "outputId": "d67bf56f-dba0-41dd-da06-24630ba6fbe9"
   },
   "outputs": [],
   "source": [
    "%cd $H/ds/\n",
    "# After trainining/transfer/finetuning do some test here\n",
    "# NOTE: SOO SLOW ..or maybe not? \n",
    "test_params = ' \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--load_evaluate best \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--train_cudnn True \\\n",
    "--test_files '+ALL_TEST_CSV+' \\\n",
    "--test_batch_size '+str(BATCH_SIZE)+' \\\n",
    "--verbosity 2'\n",
    "\n",
    "!python DeepSpeech.py $test_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLbRRiS1Wzzi"
   },
   "source": [
    "### Export the .pb file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-FuqgNIKago"
   },
   "outputs": [],
   "source": [
    "%cd $H/ds/\n",
    "#export .pb file\n",
    "exp_params = ' \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--load_evaluate \"best\" \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--lm_alpha '+str(LM_ALPHA)+' \\\n",
    "--lm_beta '+str(LM_BETA)+' \\\n",
    "--export_dir \"'+EXPORT_FOLDER+'\" \\\n",
    "--export_language \"it\" \\\n",
    "--verbosity 1'\n",
    "\n",
    "!python -u DeepSpeech.py $exp_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8IfKjgVvXD5l"
   },
   "source": [
    "### Create the pbmm file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "zuTux9ErMc6L",
    "outputId": "ec9dcd85-df30-4098-cea1-54b72bf2b824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r1.15.cpu/artifacts/public/convert_graphdef_memmapped_format ...\n",
      "Downloading: 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets create the pbmm format\n",
    "!python util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .\n",
    "!./convert_graphdef_memmapped_format --in_graph=\"$EXPORT_FOLDER\"/output_graph.pb --out_graph=\"$EXPORT_FOLDER\"/output_graph.pbmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6atYCxVLfO8f"
   },
   "outputs": [],
   "source": [
    "!python DeepSpeech.py --helpfull"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepspeech_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
