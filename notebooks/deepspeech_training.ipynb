{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBVpKaIDxr5n"
   },
   "source": [
    "# <h1> A COLAB notebook for italian DeepSpeech model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-6vTdO315En"
   },
   "source": [
    "## Install all the needed dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nf0QISLC2nes",
    "outputId": "f63fff12-6432-45a6-a8d5-67f163e3f3d4"
   },
   "outputs": [],
   "source": [
    "# shortcut for /root folder\n",
    "H = %env HOME\n",
    "%cd $H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "qK-aUbVj8Eey",
    "outputId": "86e902ae-628d-41e1-ac72-df79fe1a61df"
   },
   "outputs": [],
   "source": [
    "%env DS_VERSION 0.9.3\n",
    "# Get DeepSpeech\n",
    "\n",
    "%cd $H\n",
    "!git clone https://github.com/mozilla/DeepSpeech.git ./ds\n",
    "%cd ds\n",
    "!git checkout f2e9c85880dff94115ab510cde9ca4af7ee51c19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5k0Pegar2_7w",
    "outputId": "19777507-9779-454f-b738-ef5e4fbede46"
   },
   "outputs": [],
   "source": [
    "# Tell colab to use TF 1.x version and then install DS dependencies\n",
    "%tensorflow_version 1.x\n",
    "!pip3 install --no-cache-dir --upgrade pip==20.2.2 wheel==0.34.2 setuptools==49.6.0\n",
    "!DS_NOTENSORFLOW=y pip3 install --no-cache-dir --upgrade -e .\n",
    "!apt update && apt install -y --no-install-recommends sox libsox-fmt-mp3 pixz && apt autoremove && apt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LPiM0nZ88Yfm",
    "outputId": "3f106dd3-62f6-4b4a-fd7a-d42fb4efccf4"
   },
   "outputs": [],
   "source": [
    "# simple check before going on\n",
    "!./bin/run-tc-ldc93s1_new.sh 2 16000\n",
    "\n",
    "# this one need the kenlm.scorer so you need to install git-lfs and do a \n",
    "# git-fls pull in the deepspeech repo\n",
    "# !./bin/run-ldc93s1.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "33pDRwMPO214",
    "outputId": "1b7245d4-95ed-480f-8b64-10870534a5d5"
   },
   "outputs": [],
   "source": [
    "#the italian alphabet\n",
    "!mkdir -p /mnt/models\n",
    "!wget -O \"/mnt/models/alphabet.txt\" https://github.com/MozillaItalia/DeepSpeech-Italian-Model/raw/master/DeepSpeech/italian_alphabet.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQ-pzO3O3cEt"
   },
   "source": [
    "## tinyCV-IT, CV-IT and MAILABS dataset: uncomment and choose your fighter(s)!\n",
    "\n",
    "**WARNING: always take a look to disk space availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ladVQoVJ9drR",
    "outputId": "b2a22fe7-0881-4c7e-fc4d-e0859311c7c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the dataset you need. Don't use tinyCV-IT and CV-IT together :)\n",
    "# Keep in mind that all these stuff decompressed takes around 30GB\n",
    "# Note: english compatibility is not handled right now\n",
    "\n",
    "#tinyCV-IT (just for testing)\n",
    "'''\n",
    "\n",
    "!mkdir -p /mnt/extracted/data/cv-it_tiny\n",
    "%env CV_TINY_PATH /mnt/extracted/data/cv-it_tiny\n",
    "!wget -O - https://github.com/MozillaItalia/DeepSpeech-Italian-Model/files/4610711/cv-it_tiny.tar.gz | tar -zxv -C $CV_TINY_PATH\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#MAILABS\n",
    "'''\n",
    "\n",
    "%cd $H/ds\n",
    "# Download and prepare M-AILABS\n",
    "!python bin/import_m-ailabs.py ${IMPORT_AS_ENGLISH} \\\n",
    "  --filter_alphabet /mnt/models/alphabet.txt \\\n",
    "  --language it_IT                           \\\n",
    "  /mnt/extracted/data/M-AILABS/\n",
    "# free some space removing the MAILABS tgz\n",
    "!rm /mnt/extracted/data/M-AILABS/it_IT.tgz\n",
    "\n",
    "'''\n",
    "\n",
    "# CV-IT\n",
    "'''\n",
    "%cd $H/ds\n",
    "# Download CV\n",
    "!mkdir -p /mnt/sources\n",
    "!wget https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-5.1-2020-06-22/it.tar.gz -O /mnt/sources/it.tar.gz\n",
    "# Prepare CV\n",
    "!mkdir -p /mnt/extracted/data/cv-it/\n",
    "!tar -C /mnt/extracted/data/cv-it/ --strip-components=2 -xf /mnt/sources/it.tar.gz\n",
    "# FIX STEREO FILES\n",
    "%cd /mnt/extracted/data/cv-it/clips\n",
    "!mv common_voice_it_21431109.mp3 common_voice_it_21431109_.mp3\n",
    "!mv common_voice_it_21431655.mp3 common_voice_it_21431655_.mp3\n",
    "!sox common_voice_it_21431109_.mp3 common_voice_it_21431109.mp3 remix 1,2\n",
    "!sox common_voice_it_21431655_.mp3 common_voice_it_21431655.mp3 remix 1,2\n",
    "!rm common_voice_it_21431109_.mp3 common_voice_it_21431655_.mp3\n",
    "# START MP3->WAV CONVERSION AND CSV PREPARATION\n",
    "%cd $H/ds\n",
    "!python bin/import_cv2.py --filter_alphabet=/mnt/models/alphabet.txt /mnt/extracted/data/cv-it/\n",
    "\n",
    "# after mp3->wav conversion we can remove all mp3 files\n",
    "%cd /mnt/extracted/data/cv-it/clips\n",
    "!find . -name \"*.mp3\" -type f|xargs rm -f\n",
    "# remove the CV tar\n",
    "!rm /mnt/sources/it.tar.gz\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "O79LJ8UxrxQq",
    "outputId": "b65c63cd-e82c-4b6d-df91-9b01b9d4a85a"
   },
   "outputs": [],
   "source": [
    "# Run this if you need some space\n",
    "# !rm -rf /swift/*\n",
    "# !pip uninstall -y torch\n",
    "!rm -rf $H/.cache/pip/*\n",
    "!rm -rf $H/DeepSpeech-Italian-Model/.git/*\n",
    "!rm -rf $H/ds/.git/*\n",
    "!rm -rf $H/kenlm/.git/*\n",
    "!rm -rf /content/sample_data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vmJT9fZfHv9"
   },
   "source": [
    "## **Setup your google drive now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-axrZPOUr9f"
   },
   "source": [
    "Please, before running other cells, export your google drive path to store your model checkpoints.\n",
    "\n",
    "Probably you'll need more space than colab offers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfwjPUAB21Dt"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "30FPr_a97TD1",
    "outputId": "d16a54f2-3f20-41b7-a64e-94cca95c1499"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Edit here your base google drive path (pay attention to spaces in your path, eg \"My Drive\".)\n",
    "%env GDRIVE_PATH /content/drive/My Drive/DeepSpeech\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "zbnvvYK6Ow9V",
    "outputId": "dc18b692-17a2-47d5-e865-9077444930bc"
   },
   "outputs": [],
   "source": [
    "# Some paths\n",
    "import os\n",
    "# Customize them based on your needs!\n",
    "\n",
    "paths2print = []\n",
    "\n",
    "ALPHABET_CONFIG_PATH=\"/mnt/models/alphabet.txt\"\n",
    "paths2print.append(ALPHABET_CONFIG_PATH)\n",
    "\n",
    "SAVE_CHECKPOINT_DIR = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"ckpts/ita/deepspeech-\"+os.environ.get(\"DS_VERSION\")+\"-checkpoint\")\n",
    "paths2print.append(SAVE_CHECKPOINT_DIR)\n",
    "LOAD_CHECKPOINT_DIR = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"ckpts/eng/deepspeech-\"+os.environ.get(\"DS_VERSION\")+\"-checkpoint\")\n",
    "paths2print.append(LOAD_CHECKPOINT_DIR)\n",
    "\n",
    "# when you set 2 different folders during training, deepspeech will warn you that it will\n",
    "# be impossibile to evaluate the model with the test dataset.\n",
    "CHECKPOINT_DIR = SAVE_CHECKPOINT_DIR\n",
    "paths2print.append(CHECKPOINT_DIR)\n",
    "\n",
    "#IMPORTANT! Copy your own scorer in SCORER path!\n",
    "SCORER = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.8/kenlm.scorer\")\n",
    "paths2print.append(SCORER)\n",
    "\n",
    "EXPORT_FOLDER = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.8\")\n",
    "paths2print.append(EXPORT_FOLDER)\n",
    "\n",
    "# dir for tensorboard and logs\n",
    "SUMMARY_DIR = os.path.join(os.environ.get(\"GDRIVE_PATH\"),\"0.8/logs\")\n",
    "paths2print.append(SUMMARY_DIR)\n",
    "\n",
    "# just for a quick check \n",
    "for p in paths2print:\n",
    "  print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put here the DS english checkpoints to load model weights during transfer learning\n",
    "!mkdir -p \"$LOAD_CHECKPOINT_DIR\"\n",
    "# in this directory will be saved the italian checkpoints during the training phase\n",
    "!mkdir -p \"$SAVE_CHECKPOINT_DIR\"\n",
    "# here you can find all the logs files for tensorboard\n",
    "!mkdir -p \"$SUMMARY_DIR\"\n",
    "# print all directories created\n",
    "!du -a \"$GDRIVE_PATH\" \n",
    "\n",
    "# '''\n",
    "# example:\n",
    "\n",
    "# base dir: /content/drive/My Drive/DeepSpeech\n",
    "# eng checkpoints: /content/drive/My Drive/DeepSpeech/ckpts/eng/deepspeech-0.8.0-checkpoint\n",
    "# ita checkpoints: /content/drive/My Drive/DeepSpeech/ckpts/ita/deepspeech-0.8.0-checkpoint\n",
    "# scorer: /content/drive/My Drive/DeepSpeech/kenlm.scorer\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FXM5KLfAvzv"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7e62swUV02y"
   },
   "source": [
    "### Setup all needed params and paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7GPiNTuPAkPs",
    "outputId": "820115a1-7045-45d6-d443-df94d3561a1c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PARAM VALUES ARE SET FOR THE TINY DATASET!\n",
    "'''\n",
    "\n",
    "# BATCH SIZE = 2 for the tiny dataset!\n",
    "BATCH_SIZE=2 #128 from latest release, 64 to avoid out of memory errors ;)\n",
    "N_HIDDEN=2048\n",
    "# EPOCHS = 2 JUST FOR THE TINY DATASET!\n",
    "EPOCHS=2 #30\n",
    "LEARNING_RATE=0.0001\n",
    "DROPOUT=0.4 # from latest release\n",
    "# LM_ALPHA = None # 0.931289039105002 # from latest release\n",
    "# LM_BETA= None # 1.1834137581510284 # from latest release\n",
    "# BEAM_WIDTH=500\n",
    "\n",
    "\n",
    "do_early_stop= True\n",
    "EARLY_STOP_FLAG=\"--noearly_stop\"\n",
    "if do_early_stop:\n",
    "  print(\"do early stop\")\n",
    "  EARLY_STOP_FLAG=\"--early_stop --es_epochs 10\"\n",
    "\n",
    "\n",
    "#transfer params\n",
    "DROP_SOURCE_LAYERS = 1\n",
    "\n",
    "#other flags\n",
    "MAX_TO_KEEP = 3 # max nr of checkpoints to keep\n",
    "\n",
    "AMP_FLAG=\"--automatic_mixed_precision true\"  \n",
    "\n",
    "!mkdir -p /mnt/sources/feature_cache || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkFqEJWhMhJV"
   },
   "outputs": [],
   "source": [
    "# Train, dev and test as list of path to .csv files\n",
    "# Note: each dataset needs to be located under /mnt/extracted/data\n",
    "\n",
    "all_train_csv=!(find /mnt/extracted/data/ -type f -name '*train.csv' -printf '%p,' | sed -e 's/,$//g')\n",
    "all_dev_csv=!(find /mnt/extracted/data/ -type f -name '*dev.csv' -printf '%p,' | sed -e 's/,$//g')\n",
    "all_test_csv=!(find /mnt/extracted/data/ -type f -name '*test.csv' -printf '%p,' | sed -e 's/,$//g')\n",
    "ALL_TRAIN_CSV=all_train_csv[0]\n",
    "ALL_DEV_CSV=all_dev_csv[0]\n",
    "ALL_TEST_CSV=all_test_csv[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-wlOBFwzSUc5",
    "outputId": "5e44fe26-3586-4993-ba83-1ad3698650be"
   },
   "outputs": [],
   "source": [
    "# Build the params string for DeepSpeech.py\n",
    "\n",
    "'''\n",
    "Note if your paths contain spaces just wrap them inside \" \"\n",
    "eg:\n",
    "\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "\n",
    "'''\n",
    "\n",
    "params = \"\"\n",
    "\n",
    "# Using default lm_alpha and lm_beta \n",
    "train_params = ' \\\n",
    "--summary_dir \"'+SUMMARY_DIR+'\" \\\n",
    "--log_dir \"'+SUMMARY_DIR+'\" \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--train_cudnn True \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--train_files '+ALL_TRAIN_CSV+' \\\n",
    "--dev_files '+ALL_DEV_CSV+' \\\n",
    "--train_batch_size '+str(BATCH_SIZE)+' \\\n",
    "--dev_batch_size '+str(BATCH_SIZE)+' \\\n",
    "--n_hidden '+str(N_HIDDEN)+' \\\n",
    "--epochs '+str(EPOCHS)+' \\\n",
    "--learning_rate '+str(LEARNING_RATE)+' \\\n",
    "--dropout_rate '+str(DROPOUT)+' \\\n",
    "--max_to_keep '+str(MAX_TO_KEEP)+' \\\n",
    "'+EARLY_STOP_FLAG\n",
    "\n",
    "params = train_params\n",
    "\n",
    "# If you dont want to use data augmentation, flag this on False\n",
    "use_augmentation = False\n",
    "# transfer learning on/off\n",
    "do_transfer_learning = False\n",
    "\n",
    "\n",
    "if do_transfer_learning:\n",
    "  transfer_params = '\\\n",
    "  --drop_source_layers '+str(DROP_SOURCE_LAYERS)+'\\\n",
    "  --save_checkpoint_dir \"'+SAVE_CHECKPOINT_DIR+'\" \\\n",
    "  --load_checkpoint_dir \"'+LOAD_CHECKPOINT_DIR+'\"'\n",
    "\n",
    "  params+=transfer_params\n",
    "  AMP_FLAG=\"\"\n",
    "  !wget -O eng_checkpoints.tar.gz \"https://github.com/mozilla/DeepSpeech/releases/download/v$DS_VERSION/deepspeech-$DS_VERSION-checkpoint.tar.gz\"\n",
    "  !tar -zxv -f eng_checkpoints.tar.gz --strip 1 -C \"$LOAD_CHECKPOINT_DIR\"\n",
    "  !rm eng_checkpoints.tar.gz\n",
    "\n",
    "if use_augmentation:\n",
    "  augm = '\\\n",
    "  --feature_cache /mnt/sources/feature_cache \\\n",
    "  --cache_for_epochs 10 \\\n",
    "  --augment reverb[p=0.1,delay=50.0~30.0,decay=10.0:2.0~1.0] \\\n",
    "  --augment resample[p=0.1,rate=12000:8000~4000] \\\n",
    "  --augment codec[p=0.1,bitrate=48000:16000] \\\n",
    "  --augment volume[p=0.1,dbfs=-10:-40] \\\n",
    "  --augment pitch[p=0.1,pitch=1~0.2] \\\n",
    "  --augment tempo[p=0.1,factor=1~0.5] \\\n",
    "  --augment frequency_mask[p=0.1,n=1:3,size=1:5] \\\n",
    "  --augment time_mask[p=0.1,domain=signal,n=3:10~2,size=50:100~40] \\\n",
    "  --augment dropout[p=0.1,rate=0.05] \\\n",
    "  --augment add[p=0.1,domain=signal,stddev=0~0.5] \\\n",
    "  --augment multiply[p=0.1,domain=features,stddev=0~0.5]'\n",
    "  params+=augm\n",
    "\n",
    "params+=\" \"+AMP_FLAG\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28CMI8f7WJHX"
   },
   "source": [
    "### Start the training phase!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28CMI8f7WJHX"
   },
   "source": [
    "### WHILE TRAINING, REMEMBER TO FLUSH YOUR DRIVE TRASH FOLDER!\n",
    "#### if you are on Linux you can use a combo of google-drive-ocamlfuse and \"watch\" command to empty the .Trash/ folder!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "aoiWWxQlGSC6",
    "outputId": "2a3eca7b-564a-4425-c4d0-fe3c38c8ad97"
   },
   "outputs": [],
   "source": [
    "%cd $H/ds/\n",
    "!set -xe\n",
    "!python DeepSpeech.py $params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"$SUMMARY_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeMf4QiUWnJl"
   },
   "source": [
    "### LM OPTIMIZER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OPTMIZER = False\n",
    "\n",
    "%cd $H/ds/\n",
    "# From DS, default values: ALFA and BETA MAX=5 , N_TRIALS=2400\n",
    "LM_ALPHA_MAX=5\n",
    "LM_BETA_MAX=5\n",
    "LM_N_TRIALS=600\n",
    "# USING DEV SET FOR TUNING! TEST MUST BE THE LAST THING TO BE EVALUATED\n",
    "opt_params=' \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--train_cudnn True \\\n",
    "'+AMP_FLAG+' \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--test_files '+ALL_DEV_CSV+' \\\n",
    "--test_batch_size '+str(BATCH_SIZE)+' \\\n",
    "--n_hidden '+str(N_HIDDEN)+' \\\n",
    "--n_trials '+str(LM_N_TRIALS)+' \\\n",
    "--lm_alpha_max '+str(LM_ALPHA_MAX)+' \\\n",
    "--lm_beta_max '+str(LM_BETA_MAX)+' \\\n",
    "--feature_cache /mnt/sources/feature_cache'\n",
    "\n",
    "if RUN_OPTIMIZER:\n",
    "    !python lm_optimizer.py $opt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you have run lm_optimizer, save the best ALPHA and BETA value and run again generate_scorer_package with those new values using --default_alpha and --default_beta flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h7KomzFFp4aV",
    "outputId": "d67bf56f-dba0-41dd-da06-24630ba6fbe9"
   },
   "outputs": [],
   "source": [
    "%cd $H/ds/\n",
    "# After training/transfer/finetuning do some test here\n",
    "test_params = ' \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--load_evaluate best \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--train_cudnn True \\\n",
    "--test_files '+ALL_TEST_CSV+' \\\n",
    "--test_batch_size '+str(BATCH_SIZE)\n",
    "\n",
    "!python DeepSpeech.py $test_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLbRRiS1Wzzi"
   },
   "source": [
    "### Export the .pb file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-FuqgNIKago"
   },
   "outputs": [],
   "source": [
    "%cd $H/ds/\n",
    "#export .pb file\n",
    "exp_params = ' \\\n",
    "--alphabet_config_path '+ALPHABET_CONFIG_PATH+' \\\n",
    "--checkpoint_dir \"'+CHECKPOINT_DIR+'\" \\\n",
    "--show_progressbar true \\\n",
    "--load_evaluate \"best\" \\\n",
    "--scorer \"'+SCORER+'\" \\\n",
    "--export_dir \"'+EXPORT_FOLDER+'\" \\\n",
    "--export_language \"it\" \\\n",
    "--verbosity 1'\n",
    "\n",
    "!python -u DeepSpeech.py $exp_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8IfKjgVvXD5l"
   },
   "source": [
    "### Create the pbmm file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "zuTux9ErMc6L",
    "outputId": "ec9dcd85-df30-4098-cea1-54b72bf2b824"
   },
   "outputs": [],
   "source": [
    "#lets create the pbmm format\n",
    "!python util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .\n",
    "!./convert_graphdef_memmapped_format --in_graph=\"$EXPORT_FOLDER\"/output_graph.pb --out_graph=\"$EXPORT_FOLDER\"/output_graph.pbmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6atYCxVLfO8f"
   },
   "outputs": [],
   "source": [
    "!python DeepSpeech.py --helpfull"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepspeech_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
