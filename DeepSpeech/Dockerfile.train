# Dockerfile generated by DeepSpeech template

FROM tensorflow/tensorflow:1.15.2-gpu-py3

ARG model_language=it
ENV MODEL_LANGUAGE=$model_language

# Make sure we can extract filenames with UTF-8 chars
#ENV LANG=C.UTF-8

# Avoid keyboard-configuration step
#ENV DEBIAN_FRONTEND noninteractive

ENV DEEPSPEECH_REPO=https://github.com/mozilla/DeepSpeech.git
# checkout to 0.7.3 release
ENV DEEPSPEECH_SHA=88584941bc2ff5b91d6b11ad0a6b85da391d626b

ENV HOMEDIR /home/trainer
ENV DS_DIR $HOMEDIR/ds


RUN apt-get update && apt-get install -y --no-install-recommends \
        apt-utils \
        bash-completion \
        build-essential \
        curl \
        cmake \
        git \
        git-lfs \
        libbz2-dev \
        libeigen3-dev \
        libboost-all-dev \
        locales \
        python3-venv \
				pixz \
				sudo \
        unzip \
        wget

RUN groupadd -g 999 trainer && \
    adduser --system --uid 999 --group trainer

RUN echo "trainer ALL=(root) NOPASSWD:ALL" > /etc/sudoers.d/trainer && \
    chmod 0440 /etc/sudoers.d/trainer

# Below that point, nothing requires being root
USER trainer

WORKDIR $HOMEDIR/
# RUN git lfs install
RUN git clone $DEEPSPEECH_REPO $DS_DIR

WORKDIR $DS_DIR
RUN git checkout $DEEPSPEECH_SHA

# Setup a virtualenv otherwise we mess with the system and this is BAD.
RUN python3 -m venv venv/

ENV VIRTUAL_ENV=$DS_DIR/venv
ENV PATH=$VIRTUAL_ENV/bin:$PATH

# Build CTC decoder first, to avoid clashes on incompatible versions upgrades
RUN cd native_client/ctcdecode && make NUM_PROCESSES=$(nproc) bindings
RUN pip3 install --upgrade native_client/ctcdecode/dist/*.whl

# Prepare deps
RUN pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3

# Install DeepSpeech, no need for the decoder since we did it earlier
RUN DS_NODECODER=y pip3 install --upgrade -e .

# Build KenLM in /DeepSpeech/native_client/kenlm folder
WORKDIR $DS_DIR
RUN set -ex && \
  echo "Building KenLM" && \
  cd native_client && \
  rm -rf kenlm && \
  git clone https://github.com/kpu/kenlm && \
  cd kenlm && \
  git checkout 87e85e66c99ceff1fab2500a7c60c01da7315eec && \
  mkdir -p build && \
  cd build && \
  cmake .. && \
  make -j $(nproc)

RUN set -ex && \
  python util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .

# Training stuff
# Use our tiny dataset for training
ENV DS_TINY_TRAIN 1


ARG batch_size=64
ARG n_hidden=2048
ARG epochs=30
ARG learning_rate=0.0001
ARG dropout=0.4
ARG early_stop=1
ARG amp=1

ENV BATCH_SIZE=$batch_size
ENV N_HIDDEN=$n_hidden
ENV EPOCHS=$epochs
ENV LEARNING_RATE=$learning_rate
ENV DROPOUT=$dropout
ENV EARLY_STOP=$early_stop
ENV AMP=$amp

ARG lm_evaluate_range=
ARG english_compatible=0

ENV LM_EVALUATE_RANGE=$lm_evaluate_range
ENV ENGLISH_COMPATIBLE=$english_compatible
WORKDIR $HOMEDIR
# Copy now so that docker build can leverage caches
COPY --chown=trainer:trainer italian_alphabet.txt checks.sh generate_alphabet.sh package.sh run.sh counter.py $HOMEDIR/

COPY --chown=trainer:trainer ${MODEL_LANGUAGE}/*.sh $HOMEDIR/${MODEL_LANGUAGE}/

COPY --chown=trainer:trainer ${MODEL_LANGUAGE}/lingua_libre_skiplist.txt $HOMEDIR/${MODEL_LANGUAGE}/

# ENTRYPOINT "$HOMEDIR/run.sh"
